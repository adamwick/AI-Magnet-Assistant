// src-tauri/src/llm_service.rs

use anyhow::Result;
use async_trait::async_trait;
use reqwest::Client;
use serde::{Deserialize, Serialize};

/// æ™ºèƒ½å¤„ç†API Base URLï¼Œä¸ºä¸åŒçš„APIæœåŠ¡æ·»åŠ æ­£ç¡®çš„è·¯å¾„
fn normalize_api_base(api_base: &str) -> String {
    // ç§»é™¤æœ«å°¾çš„æ–œæ ï¼Œé¿å…åŒæ–œæ é—®é¢˜
    let trimmed_base = api_base.trim_end_matches('/');

    // å¦‚æœæ˜¯å®˜æ–¹GeminiåŸŸåä¸”æ²¡æœ‰åŒ…å«/v1betaï¼Œåˆ™è‡ªåŠ¨æ·»åŠ 
    if trimmed_base == "https://generativelanguage.googleapis.com" {
        format!("{}/v1beta", trimmed_base)
    } else if trimmed_base.starts_with("https://generativelanguage.googleapis.com") && !trimmed_base.contains("/v1beta") {
        format!("{}/v1beta", trimmed_base)
    } else if (trimmed_base.starts_with("http://") || trimmed_base.starts_with("https://"))
        && !trimmed_base.contains("/v1beta")
        && !trimmed_base.contains("/api/")
        && !trimmed_base.contains("/v1/") {
        // å¯¹äºè‡ªå®šä¹‰ä»£ç†æœåŠ¡å™¨ï¼Œå¦‚æœæ²¡æœ‰åŒ…å«APIè·¯å¾„ï¼Œå°è¯•æ·»åŠ /v1beta
        // è¿™é€‚ç”¨äºGemini Balanceç­‰ä»£ç†æœåŠ¡
        format!("{}/v1beta", trimmed_base)
    } else {
        // å¯¹äºå…¶ä»–URLï¼ˆåŒ…æ‹¬å·²ç»åŒ…å«è·¯å¾„çš„è‡ªå®šä¹‰ä»£ç†ï¼‰ï¼Œä¿æŒåŸæ ·ä½†ç§»é™¤æœ«å°¾æ–œæ 
        trimmed_base.to_string()
    }
}

// --- 0. å…¬å…±é…ç½® ---

#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct LlmConfig {
    pub provider: String,
    pub api_key: String,
    pub api_base: String,
    pub model: String,
    #[serde(default = "default_batch_size")]
    pub batch_size: u32,
}

fn default_batch_size() -> u32 {
    5
}

// --- 1. ç¬¬ä¸€é˜¶æ®µï¼šä»HTMLä¸­æå–åŸºç¡€ä¿¡æ¯ ---

/// ç¬¬ä¸€é˜¶æ®µï¼šä»HTMLä¸­æå–çš„å•ä¸ªåŸå§‹ã€æœªç»å¤„ç†çš„ç£åŠ›é“¾æ¥ä¿¡æ¯
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ExtractedBasicInfo {
    pub title: String,
    pub magnet_link: String,
    pub file_size: Option<String>,
    pub source_url: Option<String>,
}

/// ç¬¬ä¸€é˜¶æ®µï¼šæ‰¹é‡æå–ç»“æœ
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct BatchExtractBasicInfoResult {
    pub results: Vec<ExtractedBasicInfo>,
}

// --- 2. ç¬¬äºŒé˜¶æ®µï¼šåˆ†æåˆ†æ•°å’Œæ ‡ç­¾ ---

/// ç¬¬äºŒé˜¶æ®µï¼šå¯¹å•ä¸ªç£åŠ›é“¾æ¥çš„æ–‡ä»¶åˆ—è¡¨è¿›è¡Œè¯¦ç»†åˆ†æåçš„æœ€ç»ˆç»“æœ
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct DetailedAnalysisResult {
    pub title: String,           // ç²¾ç®€åçš„æ ‡é¢˜
    pub purity_score: u8,        // çº¯å‡€åº¦åˆ†æ•° (ç”±LLMè®¡ç®—)
    pub tags: Vec<String>,       // æ™ºèƒ½æ ‡ç­¾
    pub magnet_link: String,     // åŸå§‹ç£åŠ›é“¾æ¥ (ä»ç¬¬ä¸€é˜¶æ®µé€ä¼ )
    pub file_size: Option<String>, // åŸå§‹æ–‡ä»¶å¤§å° (ä»ç¬¬ä¸€é˜¶æ®µé€ä¼ )
    pub file_list: Vec<String>, // æ–‡ä»¶åˆ—è¡¨
    #[serde(skip_serializing_if = "Option::is_none")]
    pub error: Option<String>,   // é”™è¯¯ä¿¡æ¯ (å¦‚æœåˆ†æå¤±è´¥)
}

/// LLMä¸ºç¬¬äºŒé˜¶æ®µåˆ†æè¿”å›çš„åŸå§‹æ•°æ®ç»“æ„
#[derive(Serialize, Deserialize, Debug)]
struct LlmFileAnalysis {
    pub original_filename: String, // åŸå§‹æ–‡ä»¶åï¼Œç”¨äºåŒ¹é…
    pub cleaned_title: String,     // æ¸…ç†åçš„æ ‡é¢˜ (ä»…å¯¹ä¸»åª’ä½“æ–‡ä»¶æœ‰æ„ä¹‰)
    pub tags: Vec<String>,         // LLMç”Ÿæˆçš„æ ‡ç­¾ (ä»…å¯¹ä¸»åª’ä½“æ–‡ä»¶æœ‰æ„ä¹‰)
    pub purity_score: u8,          // LLMè®¡ç®—çš„çº¯å‡€åº¦åˆ†æ•° (ä»…å¯¹ä¸»åª’ä½“æ–‡ä»¶æœ‰æ„ä¹‰)
}

/// æ‰¹é‡åˆ†æçš„è¾“å…¥é¡¹
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct BatchAnalysisItem {
    pub title: String,
    pub file_list: Vec<String>,
}

/// æ‰¹é‡åˆ†æçš„ç»“æœé¡¹
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct BatchAnalysisResult {
    pub cleaned_title: String,
    pub purity_score: u8,
    pub tags: Vec<String>,
}

// --- 3. LLMå®¢æˆ·ç«¯å®šä¹‰ ---

#[async_trait]
pub trait LlmClient: Send + Sync {
    /// ç¬¬ä¸€é˜¶æ®µï¼šä»HTMLé¡µé¢æ‰¹é‡æå–åŸºç¡€ã€åŸå§‹çš„ç£åŠ›é“¾æ¥ä¿¡æ¯
    async fn batch_extract_basic_info_from_html(
        &self,
        html_content: &str,
        extraction_config: &LlmConfig,
    ) -> Result<BatchExtractBasicInfoResult>;

    /// ç¬¬äºŒé˜¶æ®µï¼šæ ¹æ®æ–‡ä»¶åˆ—è¡¨æ‰¹é‡åˆ†æåˆ†æ•°å’Œæ ‡ç­¾ï¼ˆå•ä¸ªé¡¹ç›®ï¼‰
    async fn batch_analyze_scores_and_tags(
        &self,
        original_title: &str,
        file_list: &[String],
        analysis_config: &LlmConfig,
    ) -> Result<(String, u8, Vec<String>)>;

    /// ç¬¬äºŒé˜¶æ®µï¼šçœŸæ­£çš„æ‰¹é‡åˆ†æå¤šä¸ªé¡¹ç›®
    async fn batch_analyze_multiple_items(
        &self,
        items: &[BatchAnalysisItem],
        analysis_config: &LlmConfig,
    ) -> Result<Vec<BatchAnalysisResult>>;
}

pub struct GeminiClient {
    client: Client,
}

impl GeminiClient {
    pub fn new() -> Self {
        let client = Client::new();
        Self { client }
    }
}

#[async_trait]
impl LlmClient for GeminiClient {
    async fn batch_extract_basic_info_from_html(
        &self,
        html_content: &str,
        extraction_config: &LlmConfig,
    ) -> Result<BatchExtractBasicInfoResult> {
        self.batch_extract_basic_info_impl(html_content, extraction_config).await
    }

    async fn batch_analyze_scores_and_tags(
        &self,
        original_title: &str,
        file_list: &[String],
        analysis_config: &LlmConfig,
    ) -> Result<(String, u8, Vec<String>)> {
        self.batch_analyze_scores_and_tags_impl(original_title, file_list, analysis_config)
            .await
    }

    async fn batch_analyze_multiple_items(
        &self,
        items: &[BatchAnalysisItem],
        analysis_config: &LlmConfig,
    ) -> Result<Vec<BatchAnalysisResult>> {
        self.batch_analyze_multiple_items_impl(items, analysis_config).await
    }
}

// --- 4. Gemini APIè¯·æ±‚å’Œå“åº”ç»“æ„ ---

#[derive(Serialize)]
struct GeminiRequest {
    contents: Vec<Content>,
}

#[derive(Serialize)]
struct Content {
    parts: Vec<Part>,
}

#[derive(Serialize)]
struct Part {
    text: String,
}

#[derive(Deserialize, Debug)]
struct GeminiResponse {
    candidates: Vec<Candidate>,
}

#[derive(Deserialize, Debug)]
#[serde(rename_all = "camelCase")]
struct Candidate {
    content: ContentResponse,
}

#[derive(Deserialize, Debug)]
struct ContentResponse {
    parts: Vec<PartResponse>,
}

#[derive(Deserialize, Debug)]
struct PartResponse {
    text: String,
}

// --- 5. æ ¸å¿ƒå®ç° ---

impl GeminiClient {
    /// **ç¬¬ä¸€é˜¶æ®µå®ç°**: ä»…ä»HTMLæå–åŸå§‹æ•°æ®ï¼Œä¸åšä»»ä½•ä¿®æ”¹ã€‚
    async fn batch_extract_basic_info_impl(
        &self,
        html_content: &str,
        config: &LlmConfig,
    ) -> Result<BatchExtractBasicInfoResult> {
        let normalized_base = normalize_api_base(&config.api_base);
        let url = format!(
            "{}/models/{}:generateContent?key={}",
            normalized_base, config.model, config.api_key
        );

        let prompt = format!(
            r#"
ä½œä¸ºæ•°æ®æå–å¼•æ“ï¼Œä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯ä»ä»¥ä¸‹HTMLå†…å®¹ä¸­è¯†åˆ«å‡ºæ‰€æœ‰ç£åŠ›é“¾æ¥æ¡ç›®ï¼Œå¹¶è¿”å›ä¸€ä¸ªåŒ…å« "results" æ•°ç»„çš„JSONå¯¹è±¡ã€‚

**æå–è§„åˆ™:**
1.  **è¯†åˆ«æ¡ç›®**: æ‰¾åˆ°åŒ…å«ç£åŠ›é“¾æ¥ (`magnet:?xt=`) çš„HTMLç‰‡æ®µã€‚
2.  **æå–å­—æ®µ**:
    *   `title`: æå–ä¸ç£åŠ›é“¾æ¥ç›¸å…³çš„æœ€ç›´æ¥çš„æ ‡é¢˜æ–‡æœ¬ã€‚**ä¸è¦è¿›è¡Œä»»ä½•å½¢å¼çš„æ¸…ç†ã€ä¿®æ”¹æˆ–ç¾åŒ–**ã€‚è¿”å›åŸå§‹æ–‡æœ¬ã€‚
    *   `magnet_link`: æå–å®Œæ•´çš„ç£åŠ›é“¾æ¥å­—ç¬¦ä¸²ã€‚
    *   `file_size`: æå–ä¸è¯¥æ¡ç›®ç›¸å…³çš„æ–‡ä»¶å¤§å°æ–‡æœ¬ï¼ˆä¾‹å¦‚ "1.5GB", "899MB"ï¼‰ã€‚å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™è¿”å› `null`ã€‚
    *   `source_url`: æå–ä¸è¯¥æ¡ç›®ç›¸å…³çš„è¯¦æƒ…é¡µé¢é“¾æ¥æˆ–æºé¡µé¢URLã€‚é€šå¸¸æ˜¯æ ‡é¢˜é“¾æ¥çš„hrefå±æ€§ã€‚å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™è¿”å› `null`ã€‚
3.  **ä¸¥æ ¼JSONè¾“å‡º**: è¿”å›çš„JSONå¯¹è±¡å¿…é¡»åªåŒ…å«ä¸€ä¸ª `results` é”®ï¼Œå…¶å€¼ä¸ºä¸€ä¸ªå¯¹è±¡æ•°ç»„ã€‚æ¯ä¸ªå¯¹è±¡éƒ½åŒ…å« `title`, `magnet_link`, `file_size`, `source_url` å­—æ®µã€‚

**é‡è¦æŒ‡ä»¤:**
*   **ç»å¯¹ç¦æ­¢ä¿®æ”¹æ•°æ®**: ä½ çš„ä»»åŠ¡æ˜¯æå–ï¼Œä¸æ˜¯å¤„ç†ã€‚è¿”å›ä½ æ‰¾åˆ°çš„åŸå§‹ä¿¡æ¯ã€‚
*   **æ— éœ€ç†è§£å†…å®¹**: ä¸è¦å°è¯•ç†è§£æ ‡é¢˜çš„å«ä¹‰æˆ–ç¾åŒ–å®ƒã€‚
*   **ä¿æŒé¡ºåº**: å°½å¯èƒ½æŒ‰ç…§åœ¨HTMLä¸­å‡ºç°çš„é¡ºåºåˆ—å‡ºç»“æœã€‚
*   **ä¸è¦åŒ…å«ä»»ä½•è§£é‡Š**: ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯çº¯ç²¹çš„JSONã€‚

**HTMLå†…å®¹:**
```html
{}
```

**ç¤ºä¾‹è¾“å‡º:**
```json
{{
  "results": [
    {{
      "title": "Some.Movie.Title.2023.1080p.BluRay.x264-GROUP[rartv]",
      "magnet_link": "magnet:?xt=urn:btih:abcdef123456...",
      "file_size": "2.3GB",
      "source_url": "/details/12345"
    }},
    {{
      "title": "[AD] www.example.com [AD] Another.Show.S01E01.720p.WEB-DL",
      "magnet_link": "magnet:?xt=urn:btih:fedcba654321...",
      "file_size": "500MB",
      "source_url": "https://example.com/torrent/67890"
    }}
  ]
}}
```
"#,
            html_content
        );

        let request_body = GeminiRequest {
            contents: vec![Content {
                parts: vec![Part { text: prompt }],
            }],
        };

        let response = self.client.post(&url).json(&request_body).send().await?;
        if !response.status().is_success() {
            let error_body = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("APIè¯·æ±‚å¤±è´¥: {}", error_body));
        }

        let gemini_response = response.json::<GeminiResponse>().await?;
        if let Some(candidate) = gemini_response.candidates.get(0) {
            if let Some(part) = candidate.content.parts.get(0) {
                let cleaned_text = part.text.trim().replace("```json", "").replace("```", "");
                let result: BatchExtractBasicInfoResult = serde_json::from_str(&cleaned_text)
                    .map_err(|e| {
                        anyhow::anyhow!(
                            "è§£æç¬¬ä¸€é˜¶æ®µJSONå¤±è´¥: {}. Raw text: {}",
                            e,
                            cleaned_text
                        )
                    })?;
                return Ok(result);
            }
        }
        Err(anyhow::anyhow!("Geminiå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹"))
    }

    /// **é‡æ„åçš„ç¬¬äºŒé˜¶æ®µå®ç°**: æ ¹æ®æ–°çš„ã€æ›´ç®€å•çš„é€»è¾‘åˆ†ææ ‡é¢˜ã€æ–‡ä»¶åˆ—è¡¨å’Œæ ‡ç­¾ï¼ˆæ”¯æŒé‡è¯•ï¼‰ã€‚
    async fn batch_analyze_scores_and_tags_impl(
        &self,
        original_title: &str,
        file_list: &[String],
        config: &LlmConfig,
    ) -> Result<(String, u8, Vec<String>)> {
        println!("ğŸ”§ [DEBUG] Starting single analysis for '{}' using batch method, batch_size={}",
                 original_title, config.batch_size);

        // è½¬æ¢ä¸ºæ‰¹é‡æ ¼å¼ï¼ˆå•ä¸ªé¡¹ç›®ï¼‰
        let items = vec![BatchAnalysisItem {
            title: original_title.to_string(),
            file_list: file_list.to_vec(),
        }];

        // è°ƒç”¨æ‰¹é‡åˆ†æï¼ˆåŒ…å«é‡è¯•æœºåˆ¶ï¼‰
        let results = self.batch_analyze_multiple_items_impl(&items, config).await?;

        // æå–ç¬¬ä¸€ä¸ªç»“æœ
        if let Some(result) = results.first() {
            println!("âœ… [DEBUG] Single analysis via batch method succeeded");
            Ok((result.cleaned_title.clone(), result.purity_score, result.tags.clone()))
        } else {
            Err(anyhow::anyhow!("æ‰¹é‡åˆ†ææœªè¿”å›ç»“æœ"))
        }
    }

    // try_single_analyze_scores_and_tags æ–¹æ³•å·²è¢«ç§»é™¤
    // ç°åœ¨ç»Ÿä¸€ä½¿ç”¨ try_batch_analyze_multiple_items å¤„ç†å•ä¸ªå’Œæ‰¹é‡åˆ†æ

    /// çœŸæ­£çš„æ‰¹é‡åˆ†æå®ç°ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶
    async fn batch_analyze_multiple_items_impl(
        &self,
        items: &[BatchAnalysisItem],
        config: &LlmConfig,
    ) -> Result<Vec<BatchAnalysisResult>> {
        let mut retry_count = 0;
        const MAX_RETRIES: u32 = 3;
        const RETRY_DELAY_SECONDS: u64 = 3;

        println!("ğŸ”§ [DEBUG] Starting batch analysis with {} items, batch_size={}",
                 items.len(), config.batch_size);

        loop {
            println!("ğŸ”§ [DEBUG] Attempt {} of {}", retry_count + 1, MAX_RETRIES + 1);
            match self.try_batch_analyze_multiple_items(items, config).await {
                Ok(results) => {
                    println!("âœ… [DEBUG] Batch analysis succeeded on attempt {}", retry_count + 1);
                    return Ok(results);
                }
                Err(e) => {
                    retry_count += 1;
                    println!("âŒ [DEBUG] Batch analysis failed on attempt {}: {}", retry_count, e);

                    if retry_count >= MAX_RETRIES {
                        println!("ğŸ’¥ [DEBUG] Max retries reached, giving up");
                        return Err(anyhow::anyhow!("æ‰¹é‡åˆ†æå¤±è´¥ï¼Œå·²é‡è¯•{}æ¬¡: {}", MAX_RETRIES, e));
                    }

                    println!("âš ï¸ æ‰¹é‡åˆ†æå¤±è´¥ï¼Œ{}ç§’åé‡è¯• ({}/{}): {}",
                             RETRY_DELAY_SECONDS, retry_count, MAX_RETRIES, e);

                    tokio::time::sleep(tokio::time::Duration::from_secs(RETRY_DELAY_SECONDS)).await;
                    println!("ğŸ”„ [DEBUG] Retrying now...");
                }
            }
        }
    }

    /// å°è¯•æ‰¹é‡åˆ†æï¼ˆä¸åŒ…å«é‡è¯•é€»è¾‘ï¼‰
    async fn try_batch_analyze_multiple_items(
        &self,
        items: &[BatchAnalysisItem],
        config: &LlmConfig,
    ) -> Result<Vec<BatchAnalysisResult>> {
        if items.is_empty() {
            return Ok(Vec::new());
        }

        let normalized_base = normalize_api_base(&config.api_base);
        let url = format!(
            "{}/models/{}:generateContent?key={}",
            normalized_base, config.model, config.api_key
        );

        // æ„å»ºæ‰¹é‡åˆ†æçš„ prompt
        let items_json = serde_json::to_string_pretty(items)?;

        let prompt = format!(
            r#"
ä½œä¸ºåª’ä½“èµ„æºæ‰¹é‡åˆ†æå¼•æ“ï¼Œè¯·å¯¹ä»¥ä¸‹å¤šä¸ªé¡¹ç›®è¿›è¡Œåˆ†æã€‚å¯¹æ¯ä¸ªé¡¹ç›®ï¼Œä½ éœ€è¦æ ¹æ®ä»¥ä¸‹ä¸‰é¡¹ç‹¬ç«‹ä»»åŠ¡è¿›è¡Œåˆ†æï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»“æœã€‚

**ä»»åŠ¡1ï¼šç²¾ç®€æ ‡é¢˜**
- **è¾“å…¥**: åŸå§‹æ ‡é¢˜å­—ç¬¦ä¸²ã€‚
- **è§„åˆ™**:
  1. ä»…è¾“å‡ºä½œå“åç§°å’Œå‰§é›†ä¿¡æ¯ï¼Œç§»é™¤æ‰€æœ‰å…¶ä»–å†…å®¹ï¼ˆå¹¿å‘Šã€ç½‘å€ã€æ¨å¹¿ä¿¡æ¯ã€ç”»è´¨ã€æ ¼å¼ç­‰ï¼‰ã€‚
  2. ä½œå“åç§°ï¼šå¦‚æœ‰å¤šä¸ªä½œå“åç§°æˆ–å¤šä¸ªè¯­è¨€ç‰ˆæœ¬ï¼ŒæŒ‰è‹±è¯­ â†’ æ±‰è¯­ â†’ å…¶ä»–è¯­è¨€çš„é¡ºåºå…¨éƒ¨è¾“å‡ºï¼Œç”¨ç©ºæ ¼åˆ†éš”ã€‚
  3. å‰§é›†ä¿¡æ¯ï¼šå¦‚æœ‰å¤šä¸ªå­£æ•°æˆ–é›†æ•°ï¼Œå…¨éƒ¨è¾“å‡ºï¼ˆå¦‚åŒæ—¶æœ‰ç¬¬äºŒå­£å’Œç¬¬ä¸‰å­£è¾“å‡ºS02 S03ï¼ŒåŒæ—¶æœ‰ç¬¬äºŒå­£ç¬¬ä¸‰é›†å’Œç¬¬ä¸€å­£ç¬¬äºŒé›†è¾“å‡ºS01E02 S02E03ï¼‰ï¼Œå¦‚åŸå§‹æ ‡é¢˜ä¸­æ²¡æœ‰æ˜¾ç¤ºåˆ™ä¸è¾“å‡ºã€‚
  4. æ ¼å¼ï¼šä½œå“åç§°ï¼ˆå¤šä¸ªåç§°ç”¨ç©ºæ ¼åˆ†éš”ï¼‰+ å‰§é›†ä¿¡æ¯ï¼ˆå¤šä¸ªå­£é›†ç”¨ç©ºæ ¼åˆ†éš”ï¼‰ï¼Œä¸­é—´ç”¨ç©ºæ ¼åˆ†éš”ã€‚
- **è¾“å‡º**: è¿”å›ç²¾ç®€åçš„æ ‡é¢˜å­—ç¬¦ä¸²ã€‚

**ä»»åŠ¡2ï¼šè®¡ç®—çº¯å‡€åº¦åˆ†æ•°**
- **è¾“å…¥**: æ–‡ä»¶ååˆ—è¡¨ (JSON Array)ã€‚
- **è§„åˆ™**:
  1. éå†åˆ—è¡¨ä¸­çš„æ¯ä¸ªæ–‡ä»¶åã€‚
  2. æ ¹æ®ä»¥ä¸‹æ ‡å‡†ä¸ºæ¯ä¸ªæ–‡ä»¶æ‰“åˆ†ï¼š
     - **0åˆ†**: çº¯å¹¿å‘Šæ–‡ä»¶ï¼ˆå¦‚ `.txt`, `.url`, æˆ–åŒ…å«æ˜ç¡®å¹¿å‘Šè¯è¯­çš„æ–‡ä»¶ï¼‰ã€‚
     - **80åˆ†**: æ–‡ä»¶ååŒ…å«å¹¿å‘Šä¿¡æ¯ï¼ˆå¦‚ç½‘å€ï¼‰çš„åª’ä½“èµ„æºæ–‡ä»¶ã€‚
     - **100åˆ†**: æ–‡ä»¶åå¹²å‡€ã€ä¸å«ä»»ä½•å¹¿å‘Šä¿¡æ¯çš„åª’ä½“èµ„æºæ–‡ä»¶ã€‚
  3. è®¡ç®—æ‰€æœ‰æ–‡ä»¶åˆ†æ•°çš„**å¹³å‡å€¼**ï¼Œå¹¶å››èˆäº”å…¥ä¸ºæ•´æ•°ã€‚
- **è¾“å‡º**: è¿”å›ä¸€ä¸ª0-100ä¹‹é—´çš„æ•´æ•°ä½œä¸ºæœ€ç»ˆçº¯å‡€åº¦åˆ†æ•°ã€‚

**ä»»åŠ¡3ï¼šæå–æ ‡ç­¾**
- **è¾“å…¥**: åŸå§‹æ ‡é¢˜å­—ç¬¦ä¸²ã€‚
- **è§„åˆ™**:
  1. **ä¸¥æ ¼æŒ‰é¡ºåº**æå–ä»¥ä¸‹4ç±»æ ‡ç­¾ï¼Œæ¯ç±»æœ€å¤š1ä¸ªï¼Œæ€»å…±æœ€å¤š4ä¸ªæ ‡ç­¾ï¼š
     - **ç”»è´¨**: ä½¿ç”¨æ ‡å‡†æ ¼å¼ï¼ˆå¦‚720pã€1080pã€4Kã€8Kç­‰ï¼‰
     - **è¯­è¨€**: ä½¿ç”¨è‹±è¯­è¾“å‡ºï¼ˆå¦‚Chineseã€Koreanã€Japaneseã€Englishç­‰ï¼‰
     - **å­—å¹•**: æŒ‰å­—å¹•è¯­è¨€è¾“å‡ºï¼ˆå¦‚Chinese Subã€English Subã€Korean Subç­‰ï¼‰
     - **ç‰¹æ®Šæ ¼å¼**: ä½¿ç”¨è‹±è¯­è¾“å‡ºï¼ˆå¦‚BluRayã€Dolbyã€HDRã€DVç­‰ï¼‰
  2. å¦‚æœæŸç±»ä¿¡æ¯æ— æ³•ä»åŸå§‹æ ‡é¢˜ä¸­è·å–ï¼Œè¯¥ä½ç½®ç•™ç©ºï¼Œä¸è¦ç¼–é€ ã€‚
  3. ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°é¡ºåºæ’åˆ—ï¼Œæœ€å¤šè¾“å‡º4ä¸ªæ ‡ç­¾ã€‚
- **è¾“å‡º**: è¿”å›åŒ…å«æ ‡ç­¾çš„å­—ç¬¦ä¸²æ•°ç»„ï¼Œæœ€å¤š4ä¸ªå…ƒç´ ã€‚

**è¾“å…¥æ•°æ®**:
```json
{}
```

**è¾“å‡ºè¦æ±‚**:
- ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–Markdownæ ‡è®°ã€‚
- resultsæ•°ç»„ä¸­çš„æ¯ä¸ªå¯¹è±¡å¯¹åº”è¾“å…¥ä¸­çš„ä¸€ä¸ªé¡¹ç›®ï¼ˆæŒ‰ç›¸åŒé¡ºåºï¼‰ã€‚
- `cleaned_title` å¯¹åº”ä»»åŠ¡1çš„è¾“å‡ºã€‚
- `purity_score` å¯¹åº”ä»»åŠ¡2çš„è¾“å‡ºã€‚
- `tags` å¯¹åº”ä»»åŠ¡3çš„è¾“å‡ºã€‚

**ç¤ºä¾‹è¾“å‡º:**
```json
{{
  "results": [
    {{
      "cleaned_title": "Transformers Batman å˜å½¢é‡‘åˆš è™è ä¾  S01E02 S02E03",
      "purity_score": 95,
      "tags": ["4K", "Chinese", "Chinese Sub", "BluRay"]
    }}
  ]
}}
```
"#,
            items_json
        );

        // ç§»é™¤è¯¦ç»†çš„Promptæ—¥å¿—ä»¥ç®€åŒ–è¾“å‡º
        // println!("[BATCH AI PROMPT] æ‰¹é‡åˆ†æprompt:\n---\n{}\n---", prompt);

        let request_body = GeminiRequest {
            contents: vec![Content {
                parts: vec![Part { text: prompt }],
            }],
        };

        let response = self.client.post(&url).json(&request_body).send().await?;
        if !response.status().is_success() {
            let error_body = response.text().await.unwrap_or_default();
            return Err(anyhow::anyhow!("APIè¯·æ±‚å¤±è´¥: {}", error_body));
        }

        let gemini_response = response.json::<GeminiResponse>().await?;
        if let Some(candidate) = gemini_response.candidates.get(0) {
            if let Some(part) = candidate.content.parts.get(0) {
                let cleaned_text = part.text.trim().replace("```json", "").replace("```", "");

                // ç§»é™¤è¯¦ç»†çš„å“åº”æ—¥å¿—ä»¥ç®€åŒ–è¾“å‡º
                // println!("[BATCH AI RESPONSE] æ‰¹é‡åˆ†æå“åº”:\n---\n{}\n---", cleaned_text);

                #[derive(Deserialize)]
                struct BatchAnalysisResponse {
                    results: Vec<BatchAnalysisResult>,
                }

                let batch_response: BatchAnalysisResponse = serde_json::from_str(&cleaned_text)
                    .map_err(|e| {
                        anyhow::anyhow!(
                            "è§£ææ‰¹é‡åˆ†æå“åº”JSONå¤±è´¥: {}. Raw text: {}",
                            e,
                            cleaned_text
                        )
                    })?;

                // éªŒè¯ç»“æœæ•°é‡æ˜¯å¦åŒ¹é…
                if batch_response.results.len() != items.len() {
                    return Err(anyhow::anyhow!(
                        "æ‰¹é‡åˆ†æç»“æœæ•°é‡ä¸åŒ¹é…: æœŸæœ›{}, å®é™…{}",
                        items.len(),
                        batch_response.results.len()
                    ));
                }

                return Ok(batch_response.results);
            }
        }
        Err(anyhow::anyhow!("Geminiå“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹"))
    }
}

// --- 6. å…¬å…±APIå‡½æ•° ---
// æ³¨æ„ï¼šåŸæœ‰çš„å…¬å…±APIå‡½æ•°å·²è¢«åˆ é™¤ï¼Œå› ä¸ºå®ƒä»¬æœªè¢«ä½¿ç”¨
// æ‰€æœ‰AIè°ƒç”¨ç°åœ¨éƒ½é€šè¿‡LlmClient traitè¿›è¡Œ

/// æµ‹è¯•ä¸LLMæä¾›å•†çš„è¿æ¥ã€‚
pub async fn test_connection(config: &LlmConfig) -> Result<String> {
    let normalized_base = normalize_api_base(&config.api_base);
    let url = format!(
        "{}/models/{}:generateContent?key={}",
        normalized_base, config.model, config.api_key
    );

    // ç®€åŒ–è°ƒè¯•ä¿¡æ¯
    println!("ğŸ”§ Testing connection to: {}", url);
    let request_body = GeminiRequest {
        contents: vec![Content {
            parts: vec![Part {
                text: "ä½ å¥½".to_string(),
            }],
        }],
    };
    let client = Client::new();
    let response = client.post(&url).json(&request_body).send().await?;

    let status = response.status();
    if status.is_success() {
        println!("âœ… Connection successful (Status: {}).", status);
        Ok("è¿æ¥æˆåŠŸ".to_string())
    } else {
        let error_body = response.text().await.unwrap_or_default();
        println!("âŒ Connection failed (Status: {}): {}", status, error_body);

        // ä¸ºå¸¸è§é”™è¯¯æä¾›æ›´å‹å¥½çš„æç¤º
        let error_message = match status.as_u16() {
            401 => "è®¤è¯å¤±è´¥ï¼šè¯·æ£€æŸ¥API Keyæ˜¯å¦æ­£ç¡®".to_string(),
            403 => "è®¿é—®è¢«æ‹’ç»ï¼šè¯·æ£€æŸ¥API Keyæƒé™".to_string(),
            404 => "APIè·¯å¾„ä¸å­˜åœ¨ï¼šè¯·æ£€æŸ¥API Base URLæ˜¯å¦æ­£ç¡®".to_string(),
            405 => "è¯·æ±‚æ–¹æ³•ä¸å…è®¸ï¼šAPIè·¯å¾„å¯èƒ½ä¸æ­£ç¡®".to_string(),
            500 => "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼šå¯èƒ½æ˜¯API Keyæ— æ•ˆæˆ–æ¨¡å‹åç§°é”™è¯¯".to_string(),
            _ => format!("APIè¿æ¥å¤±è´¥ (çŠ¶æ€ç : {})", status),
        };

        Err(anyhow::anyhow!("{}: {}", error_message, error_body))
    }
}