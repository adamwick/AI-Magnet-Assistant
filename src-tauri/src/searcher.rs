use anyhow::{Result, anyhow};
// ç§»é™¤æœªä½¿ç”¨çš„é¡¶å±‚å¯¼å…¥ï¼ˆreqwest å·²é€šè¿‡å…·ä½“è·¯å¾„ä½¿ç”¨ï¼‰
use scraper::{Html, Selector};
use futures::future::join_all;
use std::sync::Arc;
use crate::llm_service::{LlmClient, GeminiClient, LlmConfig};

// ç»Ÿä¸€çš„æ—¥å¿—å®
macro_rules! search_log {
    (info, $($arg:tt)*) => {
        println!("ğŸ” {}", format!($($arg)*))
    };
    (success, $($arg:tt)*) => {
        println!("âœ… {}", format!($($arg)*))
    };
    (warn, $($arg:tt)*) => {
        println!("âš ï¸ {}", format!($($arg)*))
    };
    (error, $($arg:tt)*) => {
        println!("âŒ {}", format!($($arg)*))
    };
    (ai, $($arg:tt)*) => {
        println!("ğŸ¤– {}", format!($($arg)*))
    };
    (stats, $($arg:tt)*) => {
        println!("ğŸ“Š {}", format!($($arg)*))
    };
}

// ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
fn handle_request_error(url: &str, error: reqwest::Error) -> anyhow::Error {
    search_log!(error, "Request failed for {}: {}", url, error);
    anyhow!("Request failed: {}", error)
}

/// å®‰å…¨æˆªæ–­å­—ç¬¦ä¸²ï¼Œé¿å…åˆ‡åˆ°å¤šå­—èŠ‚å­—ç¬¦ä¸­é—´
fn safe_truncate(s: &str, max_bytes: usize) -> &str {
    if s.len() <= max_bytes {
        return s;
    }

    // æ‰¾åˆ°ä¸è¶…è¿‡max_bytesçš„æœ€å¤§å­—ç¬¦è¾¹ç•Œ
    let mut end = max_bytes;
    while end > 0 && !s.is_char_boundary(end) {
        end -= 1;
    }
    &s[..end]
}

/// æ¸…ç†HTMLæ ‡ç­¾å’Œå®ä½“
fn clean_html_text(text: &str) -> String {
    // ç§»é™¤HTMLæ ‡ç­¾
    let re_tags = regex::Regex::new(r"<[^>]*>").unwrap();
    let text = re_tags.replace_all(text, "");

    // è§£ç å¸¸è§çš„HTMLå®ä½“
    let text = text
        .replace("&amp;", "&")
        .replace("&lt;", "<")
        .replace("&gt;", ">")
        .replace("&quot;", "\"")
        .replace("&#39;", "'")
        .replace("&nbsp;", " ");

    // æ¸…ç†å¤šä½™çš„ç©ºæ ¼
    text.trim().replace("  ", " ")
}

#[derive(Debug, serde::Serialize, serde::Deserialize, Clone)]
pub struct SearchResult {
    pub title: String,
    pub magnet_link: String,
    pub file_size: Option<String>,
    pub upload_date: Option<String>,
    pub file_list: Vec<String>,
    pub source_url: Option<String>,
    pub score: Option<u8>,
    pub tags: Option<Vec<String>>,
}

/// æœç´¢å¼•æ“æä¾›å•†ç‰¹æ€§
#[async_trait::async_trait]
pub trait SearchProvider: Send + Sync {
    #[allow(dead_code)]
    fn name(&self) -> &str;
    async fn search(&self, query: &str, page: u32) -> Result<Vec<SearchResult>>;
}

/// clmclm.com æœç´¢å¼•æ“å®ç°
pub struct ClmclmProvider {
    client: reqwest::Client,
    pub base_url: String,
}

impl ClmclmProvider {
    pub fn with_base_url(base_url: &str) -> Self {
        let client = reqwest::Client::builder()
            .user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36")
            .timeout(std::time::Duration::from_secs(30))
            .build()
            .expect("Failed to create HTTP client");

        Self {
            client,
            base_url: base_url.trim_end_matches('/').to_string(),
        }
    }

    pub fn new() -> Self {
        Self::with_base_url("http://clmclm.com")
    }
}

#[async_trait::async_trait]
impl SearchProvider for ClmclmProvider {
    fn name(&self) -> &str {
        "clmclm.com"
    }

    async fn search(&self, query: &str, page: u32) -> Result<Vec<SearchResult>> {
        let url = format!("{}/search-{}-1-1-{}.html", self.base_url, query, page);
        search_log!(info, "Searching: {}", url);

        let response = self.client
            .get(&url)
            .send()
            .await
            .map_err(|e| handle_request_error(&url, e))?;

        if !response.status().is_success() {
            search_log!(error, "HTTP error {} for {}", response.status(), url);
            return Err(anyhow!("HTTP error {}: {}", response.status(), url));
        }

        let html = response.text().await?;
        let results = self.parse_results(&html)?;
        search_log!(stats, "Found {} results on page {}", results.len(), page);
        Ok(results)
    }
}

impl ClmclmProvider {
    fn parse_results(&self, html: &str) -> Result<Vec<SearchResult>> {
        let document = Html::parse_document(html);

        let row_selector = Selector::parse("div.ssbox")
            .map_err(|e| anyhow!("Invalid CSS selector: {}", e))?;
        let title_selector = Selector::parse("div.title > h3 > a")
            .map_err(|e| anyhow!("Invalid CSS selector: {}", e))?;
        let magnet_selector = Selector::parse("div.sbar a[href^=\"magnet:\"]")
            .map_err(|e| anyhow!("Invalid CSS selector: {}", e))?;
        let file_list_selector = Selector::parse("ul > li")
            .map_err(|e| anyhow!("Invalid CSS selector: {}", e))?;

        let mut results = Vec::new();

        for element in document.select(&row_selector) {
            let title_element = element.select(&title_selector).next();
            let magnet_element = element.select(&magnet_selector).next();

            if let (Some(title_node), Some(magnet_node)) = (title_element, magnet_element) {
                let title = clean_html_text(&title_node.text().collect::<String>());
                let source_url = title_node.value().attr("href").map(|s| format!("{}{}", self.base_url, s));

                if let Some(magnet_link) = magnet_node.value().attr("href") {
                    // å°è¯•ä»æ‰€æœ‰spanä¸­æ‰¾åˆ°æ–‡ä»¶å¤§å°
                    let mut file_size = None;
                    let span_selector = Selector::parse("div.sbar span").unwrap();
                    for span in element.select(&span_selector) {
                        let span_text = span.text().collect::<String>();
                        let span_text = span_text.trim();
                        if span_text.starts_with("å¤§å°:") {
                            file_size = Some(span_text.replace("å¤§å°:", "").trim().to_string());
                            break;
                        }
                    }

                    // æå–çœŸå®çš„æ–‡ä»¶åˆ—è¡¨
                    let mut file_list = Vec::new();
                    for li_element in element.select(&file_list_selector) {
                        let file_text = li_element.text().collect::<String>();
                        let file_text = file_text.trim();

                        // è§£ææ–‡ä»¶åå’Œå¤§å°ï¼Œæ ¼å¼é€šå¸¸æ˜¯ "æ–‡ä»¶å å¤§å°"
                        if !file_text.is_empty() {
                            // åˆ†å‰²æ–‡ä»¶åå’Œå¤§å°ï¼Œå¤§å°é€šå¸¸åœ¨æœ€å
                            let parts: Vec<&str> = file_text.split_whitespace().collect();
                            if parts.len() >= 2 {
                                // æ£€æŸ¥æœ€åä¸€éƒ¨åˆ†æ˜¯å¦æ˜¯æ–‡ä»¶å¤§å°ï¼ˆåŒ…å« GB, MB, KB ç­‰ï¼‰
                                let last_part = parts[parts.len() - 1];
                                if last_part.contains("GB") || last_part.contains("MB") || last_part.contains("KB") || last_part.contains("TB") {
                                    // æ–‡ä»¶åæ˜¯é™¤äº†æœ€åä¸€éƒ¨åˆ†çš„æ‰€æœ‰å†…å®¹
                                    let filename = parts[..parts.len() - 1].join(" ");
                                    if !filename.is_empty() {
                                        file_list.push(filename);
                                    }
                                } else {
                                    // å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°å¤§å°ï¼Œå°±æŠŠæ•´ä¸ªæ–‡æœ¬ä½œä¸ºæ–‡ä»¶å
                                    file_list.push(file_text.to_string());
                                }
                            } else {
                                // å¦‚æœåªæœ‰ä¸€ä¸ªéƒ¨åˆ†ï¼Œç›´æ¥ä½œä¸ºæ–‡ä»¶å
                                file_list.push(file_text.to_string());
                            }
                        }
                    }

                    // å¦‚æœæ²¡æœ‰è§£æåˆ°æ–‡ä»¶åˆ—è¡¨ï¼Œä½¿ç”¨åŸºäºæ ‡é¢˜çš„ç”Ÿæˆæ–¹æ³•ä½œä¸ºåå¤‡
                    if file_list.is_empty() {
                        file_list = self.extract_file_list_from_magnet(magnet_link, &title);
                    }

                    results.push(SearchResult {
                        title,
                        magnet_link: magnet_link.to_string(),
                        file_size,
                        upload_date: None, // clmclm.com doesn't provide upload date
                        file_list,
                        source_url,
                        score: None,
                        tags: None,
                    });
                }
            }
        }

        Ok(results)
    }

    /// ä»ç£åŠ›é“¾æ¥å’Œæ ‡é¢˜ä¸­æå–æ–‡ä»¶åˆ—è¡¨ï¼ˆåŸºäºæ ‡é¢˜ç”Ÿæˆç›¸å…³æ–‡ä»¶åˆ—è¡¨ï¼‰
    fn extract_file_list_from_magnet(&self, magnet_link: &str, title: &str) -> Vec<String> {
        if !magnet_link.contains("btih:") {
            return vec![];
        }

        generate_file_list_from_title(title)
    }
}

/// é€šç”¨æœç´¢å¼•æ“æä¾›å•†ï¼Œæ”¯æŒè‡ªå®šä¹‰URLæ¨¡æ¿å’ŒAIæ™ºèƒ½è¯†åˆ«
pub struct GenericProvider {
    name: String,
    url_template: String,
    client: reqwest::Client,
    llm_client: Option<Arc<dyn LlmClient>>,
    extraction_config: Option<LlmConfig>,  // HTMLæå–é…ç½®ï¼ˆåˆ†æç”±å‰ç«¯å¤„ç†ï¼‰
    priority_keywords: Vec<String>,
}

impl GenericProvider {
    pub fn new(name: String, url_template: String) -> Self {
        let client = reqwest::Client::builder()
            .user_agent("Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36")
            .timeout(std::time::Duration::from_secs(30))
            // reqwesté»˜è®¤å¯ç”¨gzip/deflateè§£å‹ï¼Œä¸éœ€è¦æ˜¾å¼è®¾ç½®
            .build()
            .expect("Failed to create HTTP client");

        Self {
            name,
            url_template,
            client,
            llm_client: None,
            extraction_config: None,
            priority_keywords: Vec::new(),
        }
    }

    /// è®¾ç½® LLM å®¢æˆ·ç«¯å’Œï¼ˆç¬¬ä¸€é˜¶æ®µ HTML æå–ç”¨çš„ï¼‰é…ç½®
    pub fn with_llm_client_and_config(
        mut self,
        llm_client: Arc<dyn LlmClient>,
        extraction_config: LlmConfig,
    ) -> Self {
        self.llm_client = Some(llm_client);
        self.extraction_config = Some(extraction_config);
        self
    }

    /// è®¾ç½®ä¼˜å…ˆå…³é”®è¯ç”¨äºåŒ¹é…
    pub fn with_priority_keywords(mut self, keywords: Vec<String>) -> Self {
        self.priority_keywords = keywords;
        self
    }
}

#[async_trait::async_trait]
impl SearchProvider for GenericProvider {
    fn name(&self) -> &str {
        &self.name
    }

    async fn search(&self, query: &str, page: u32) -> Result<Vec<SearchResult>> {
        // æ›¿æ¢URLæ¨¡æ¿ä¸­çš„å ä½ç¬¦
        let mut url = self.url_template
            .replace("{keyword}", query);

        // Handle different page numbering systems
        if url.contains("{page-1}") {
            // 0-based pagination: subtract 1 from page number
            let zero_based_page = if page > 0 { page - 1 } else { 0 };
            url = url.replace("{page-1}", &zero_based_page.to_string());
        } else {
            // 1-based pagination (default)
            url = url.replace("{page}", &page.to_string());
        }

        search_log!(info, "Searching: {}", url);

        let response = self.client
            .get(&url)
            .header("Accept", "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7")
            .header("Accept-Language", "en-US,en;q=0.9")
            .header("Accept-Encoding", "gzip, deflate, br")
            .header("Cache-Control", "no-cache")
            .header("Pragma", "no-cache")
            .header("Sec-Ch-Ua", "\"Google Chrome\";v=\"131\", \"Chromium\";v=\"131\", \"Not_A Brand\";v=\"24\"")
            .header("Sec-Ch-Ua-Mobile", "?0")
            .header("Sec-Ch-Ua-Platform", "\"Windows\"")
            .header("Sec-Fetch-Dest", "document")
            .header("Sec-Fetch-Mode", "navigate")
            .header("Sec-Fetch-Site", "cross-site")
            .header("Sec-Fetch-User", "?1")
            .header("Upgrade-Insecure-Requests", "1")
            .header("Referer", "https://www.google.com/")
            .send()
            .await
            .map_err(|e| handle_request_error(&url, e))?;

        if !response.status().is_success() {
            search_log!(error, "HTTP error {} for {}", response.status(), url);
            return Err(anyhow!("HTTP error: {}", response.status()));
        }

        // è·å–å“åº”æ–‡æœ¬ï¼ˆreqwestè‡ªåŠ¨å¤„ç†å‹ç¼©ï¼‰
        let html = response.text().await
            .map_err(|e| anyhow!("Failed to read response: {}", e))?;

        // æ£€æŸ¥å“åº”å†…å®¹ç±»å‹
        let is_javascript = html.trim_start().starts_with("\"use strict\"") ||
                           html.contains("webpack") ||
                           html.contains("self.webpackChunk");

        if is_javascript {
            search_log!(warn, "ç½‘ç«™è¿”å›JavaScriptä»£ç ï¼Œå¯èƒ½æ˜¯SPAæˆ–æœ‰åçˆ¬è™«æœºåˆ¶ï¼Œè·³è¿‡å¤„ç†");
            return Ok(Vec::new());
        }

        if html.contains('ï¿½') {
            search_log!(warn, "HTMLåŒ…å«ä¹±ç å­—ç¬¦ï¼Œå¯èƒ½å­˜åœ¨ç¼–ç é—®é¢˜");
        }

        // åªåœ¨å‡ºç°é—®é¢˜æ—¶æ˜¾ç¤ºHTMLé¢„è§ˆ
        if html.contains('ï¿½') || is_javascript {
            let preview = safe_truncate(&html, 500);
            search_log!(info, "HTML preview (å‰500å­—ç¬¦ï¼Œç”¨äºè¯Šæ–­):");
            println!("---START---");
            println!("{preview}");
            println!("---END---");
        }

        // ç®€å•æ£€æŸ¥å†…å®¹
        let magnet_count = html.matches("magnet:").count();
        if magnet_count == 0 {
            let error_count = html.matches("404").count() + html.matches("Not Found").count();
            if error_count > 0 {
                search_log!(warn, "å¯èƒ½æ”¶åˆ°äº†é”™è¯¯é¡µé¢ï¼ŒåŒ…å« {} ä¸ªé”™è¯¯æŒ‡ç¤ºç¬¦", error_count);
            }
        }

        // å¯¹äºè‡ªå®šä¹‰æœç´¢å¼•æ“ï¼Œä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«æµç¨‹
        let results = if let Some(llm_client) = &self.llm_client {
            self.analyze_html_with_ai(&html, llm_client.clone()).await?
        } else {
            self.parse_generic_results(&html)?
        };

        search_log!(stats, "Found {} results on page {}", results.len(), page);
        Ok(results)
    }
}

impl GenericProvider {
    /// ä½¿ç”¨AIåˆ†ææ•´ä¸ªHTMLå†…å®¹
    async fn analyze_html_with_ai(&self, html: &str, llm_client: Arc<dyn LlmClient>) -> Result<Vec<SearchResult>> {
        search_log!(ai, "Phase 1: Extracting basic info from HTML...");

        // ç¬¬ä¸€é˜¶æ®µï¼šè®©AIä»HTMLä¸­æå–æ‰€æœ‰ç£åŠ›é“¾æ¥å’ŒåŸºç¡€ä¿¡æ¯
        match self.extract_torrents_from_html_with_ai(html, llm_client.clone()).await {
            Ok(results) => {
                if results.is_empty() {
                    search_log!(warn, "AI extraction found no results. Falling back to basic parsing");
                    return self.parse_generic_results(html);
                }

                search_log!(ai, "Phase 2: Separating priority results...");
                let (priority_results, regular_results) = self.separate_priority_results(results);

                search_log!(success, "AI extraction completed: {} priority and {} regular results",
                         priority_results.len(), regular_results.len());

                // åˆå¹¶ç»“æœï¼šä¼˜å…ˆç»“æœåœ¨å‰ï¼Œæ™®é€šç»“æœåœ¨å
                let mut final_results = priority_results;
                final_results.extend(regular_results);
                Ok(final_results)
            }
            Err(e) => {
                search_log!(warn, "AI HTML analysis failed: {}, falling back to basic parsing", e);
                self.parse_generic_results(html)
            }
        }
    }

    /// ä½¿ç”¨AIä»HTMLä¸­æå–ç§å­ä¿¡æ¯
    async fn extract_torrents_from_html_with_ai(&self, html: &str, llm_client: Arc<dyn LlmClient>) -> Result<Vec<SearchResult>> {
        // é™åˆ¶HTMLé•¿åº¦ä»¥é¿å…è¶…å‡ºAI tokené™åˆ¶ (250k tokensæ¨¡å‹ï¼Œä½¿ç”¨80kå­—ç¬¦çº¦120k tokens)
        let truncated_html = if html.len() > 80000 {
            search_log!(info, "HTML too long ({} chars), truncating to 80k chars", html.len());
            safe_truncate(html, 80000)
        } else {
            html
        };

        // ç›´æ¥ä¼ é€’åŸå§‹HTMLç»™AIæœåŠ¡ï¼Œè®©llm_service.rsè´Ÿè´£æ„å»ºæç¤ºè¯
        match self.call_ai_for_html_analysis(truncated_html, llm_client).await {
            Ok(ai_results) => Ok(ai_results),
            Err(e) => Err(anyhow!("AI HTML analysis failed: {}", e))
        }
    }

    /// ç›´æ¥è°ƒç”¨AIè¿›è¡ŒHTMLåˆ†æ
    async fn call_ai_for_html_analysis(&self, html_content: &str, llm_client: Arc<dyn LlmClient>) -> Result<Vec<SearchResult>> {
        // è·å–æå–é…ç½®
        let extraction_config = self.extraction_config.as_ref()
            .ok_or_else(|| anyhow!("Extraction config not available"))?;

        // å°†åŸå§‹HTMLä¼ é€’ç»™AIæœåŠ¡ï¼Œç”±llm_service.rsæ„å»ºæç¤ºè¯
        match llm_client.batch_extract_basic_info_from_html(html_content, extraction_config).await {
            Ok(batch_result) => {
                // AIè¿”å›çš„JSONå“åº”è¢«è§£æåˆ°batch_result.resultsä¸­
                // æˆ‘ä»¬éœ€è¦å°†æ•´ä¸ªç»“æœä¼ é€’ç»™è§£æå‡½æ•°
                self.parse_ai_html_response_from_batch(batch_result)
            }
            Err(e) => {
                search_log!(error, "AI HTMLåˆ†æå¤±è´¥: {}", e);
                search_log!(ai, "å‘é€ç»™AIçš„HTMLé•¿åº¦: {} å­—ç¬¦", html_content.len());
                search_log!(ai, "HTMLå‰500å­—ç¬¦é¢„è§ˆ: {}", safe_truncate(html_content, 500));
                Err(anyhow!("AI HTML analysis failed: {}", e))
            }
        }
    }

    /// è§£æAIè¿”å›çš„HTMLåˆ†æç»“æœ
    fn parse_ai_html_response_from_batch(&self, batch_result: crate::llm_service::BatchExtractBasicInfoResult) -> Result<Vec<SearchResult>> {
        // ç›´æ¥ä»BatchExtractBasicInfoResultè½¬æ¢ä¸ºSearchResult
        let mut results = Vec::new();

        for basic_info in batch_result.results {
            // éªŒè¯ç£åŠ›é“¾æ¥æ ¼å¼
            if !basic_info.magnet_link.starts_with("magnet:?xt=urn:btih:") {
                println!("âš ï¸ Invalid magnet link format, skipping: {}", basic_info.magnet_link);
                continue;
            }

            // ç¬¬ä¸€é˜¶æ®µAIåªæå–åŸºç¡€ä¿¡æ¯ï¼Œæ–‡ä»¶åˆ—è¡¨éœ€è¦æ ¹æ®æ ‡é¢˜ç”Ÿæˆ
            let file_list = generate_file_list_from_title(&basic_info.title);

            // å¤„ç† source_urlï¼šç»Ÿä¸€ä½¿ç”¨ normalize_source_url
            let source_url = basic_info
                .source_url
                .map(|href| self.normalize_source_url(&href));

            results.push(SearchResult {
                title: clean_html_text(&basic_info.title),
                magnet_link: basic_info.magnet_link,
                file_size: basic_info.file_size,
                upload_date: None, // ç¬¬ä¸€é˜¶æ®µä¸æå–ä¸Šä¼ æ—¥æœŸ
                file_list,
                source_url,
                score: None,
                tags: None,
            });
        }

        Ok(results)
    }

    /// ä»URLæ¨¡æ¿ä¸­æå–åŸºç¡€URLï¼ˆç”¨äºæ„å»ºå®Œæ•´çš„source_urlï¼‰
    fn extract_base_url_from_template(&self) -> Option<String> {
        if let Ok(parsed_url) = url::Url::parse(&self.url_template) {
            if let Some(host) = parsed_url.host_str() {
                let scheme = parsed_url.scheme();
                return Some(format!("{scheme}://{host}"));
            }
        }
        None
    }

    /// æ ‡å‡†åŒ–source_urlï¼Œå°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
    fn normalize_source_url(&self, href: &str) -> String {
        if href.starts_with("http://") || href.starts_with("https://") {
            href.to_string()
        } else if href.starts_with("/") {
            // ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦ä»URLæ¨¡æ¿ä¸­æå–åŸºç¡€åŸŸå
            self.extract_base_url_from_template()
                .map(|base| format!("{base}{href}"))
                .unwrap_or_else(|| href.to_string())
        } else {
            href.to_string()
        }
    }

    // æ³¨æ„ï¼šparse_ai_html_response å‡½æ•°å·²è¢«åˆ é™¤ï¼Œå› ä¸ºç°åœ¨ç›´æ¥ä½¿ç”¨ BatchExtractBasicInfoResult

    /// åˆ†ç¦»ä¼˜å…ˆç»“æœå’Œæ™®é€šç»“æœ
    fn separate_priority_results(&self, results: Vec<SearchResult>) -> (Vec<SearchResult>, Vec<SearchResult>) {
        if self.priority_keywords.is_empty() {
            return (Vec::new(), results);
        }

        let (priority_results, regular_results): (Vec<_>, Vec<_>) = results.into_iter().partition(|result| {
            let title_lower = result.title.to_lowercase();
            self.priority_keywords.iter().any(|keyword| title_lower.contains(&keyword.to_lowercase()))
        });

        if !priority_results.is_empty() {
            println!("ğŸŒŸ Found {} priority results.", priority_results.len());
        }

        (priority_results, regular_results)
    }

    // æ³¨æ„ï¼šapply_detailed_ai_analysis æ–¹æ³•å·²è¢«ç§»é™¤
    // ç°åœ¨ç»Ÿä¸€ä½¿ç”¨å‰ç«¯çš„å¹¶è¡Œåˆ†ææµç¨‹ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ

    fn parse_generic_results(&self, html: &str) -> Result<Vec<SearchResult>> {
        let document = Html::parse_document(html);
        let mut results = Vec::new();

        println!("ğŸ” Parsing generic HTML content...");

        // å°è¯•æŸ¥æ‰¾å¸¸è§çš„ç£åŠ›é“¾æ¥æ¨¡å¼
        let magnet_regex = regex::Regex::new(r"magnet:\?xt=urn:btih:[a-fA-F0-9]{40}[^&\s]*")
            .map_err(|e| anyhow!("Invalid regex: {}", e))?;

        // å°è¯•è§£æè¡¨æ ¼ç»“æ„ï¼ˆæœ€å¸¸è§çš„ç§å­ç«™ç‚¹å¸ƒå±€ï¼‰
        if let Ok(table_selector) = Selector::parse("table") {
            for table in document.select(&table_selector) {
                if let Ok(row_selector) = Selector::parse("tr") {
                    for row in table.select(&row_selector) {
                        if let Some(result) = self.parse_table_row(&row, &magnet_regex) {
                            results.push(result);
                        }
                    }
                }
            }
        }

        // å¦‚æœè¡¨æ ¼è§£ææ²¡æœ‰ç»“æœï¼Œå°è¯•é€šç”¨è§£æ
        if results.is_empty() {
            results = self.parse_generic_fallback(&document, &magnet_regex)?;
        }

        println!("ğŸ“Š Extracted {} unique results from generic HTML", results.len());
        Ok(results)
    }

    /// è§£æè¡¨æ ¼è¡Œï¼Œæå–æ ‡é¢˜ã€ç£åŠ›é“¾æ¥å’Œæ–‡ä»¶å¤§å°
    fn parse_table_row(&self, row: &scraper::ElementRef, magnet_regex: &regex::Regex) -> Option<SearchResult> {
        let row_html = row.html();

        // æŸ¥æ‰¾ç£åŠ›é“¾æ¥
        let magnet_link = magnet_regex.find(&row_html)?.as_str().to_string();

        // æå–å•å…ƒæ ¼
        let cell_selector = Selector::parse("td").ok()?;
        let cells: Vec<_> = row.select(&cell_selector).collect();

        if cells.is_empty() {
            return None;
        }

        let mut title = None;
        let mut file_size = None;
        let mut upload_date = None;
        let mut source_url = None;

        // åˆ†ææ¯ä¸ªå•å…ƒæ ¼
        for (i, cell) in cells.iter().enumerate() {
            let cell_text = cell.text().collect::<String>().trim().to_string();

            // ç¬¬ä¸€ä¸ªå•å…ƒæ ¼é€šå¸¸æ˜¯æ ‡é¢˜
            if i == 0 && title.is_none() {
                if let Ok(link_selector) = Selector::parse("a") {
                    if let Some(link) = cell.select(&link_selector).next() {
                        let link_text = link.text().collect::<String>().trim().to_string();
                        if !link_text.is_empty() && !link_text.starts_with("magnet:") {
                            title = Some(clean_html_text(&link_text));
                            // æå–source_url
                            if let Some(href) = link.value().attr("href") {
                                source_url = Some(self.normalize_source_url(href));
                            }
                        }
                    }
                }
                // å¦‚æœæ²¡æœ‰é“¾æ¥ï¼Œä½¿ç”¨å•å…ƒæ ¼æ–‡æœ¬
                if title.is_none() && !cell_text.is_empty() && cell_text.len() > 5 {
                    title = Some(clean_html_text(&cell_text));
                }
            }

            // æŸ¥æ‰¾æ–‡ä»¶å¤§å°ï¼ˆåŒ…å« GB, MB, KB, TB çš„å•å…ƒæ ¼ï¼‰
            if file_size.is_none() && self.is_file_size(&cell_text) {
                file_size = Some(cell_text.clone());
            }

            // æŸ¥æ‰¾æ—¥æœŸï¼ˆåŒ…å«æ—¥æœŸæ ¼å¼çš„å•å…ƒæ ¼ï¼‰
            if upload_date.is_none() && self.is_date(&cell_text) {
                upload_date = Some(cell_text);
            }
        }

        // å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜ï¼Œå°è¯•ä»ç£åŠ›é“¾æ¥æå–
        let final_title = title.unwrap_or_else(|| self.extract_title_from_magnet(&magnet_link));

        let file_list = generate_file_list_from_title(&final_title);

        Some(SearchResult {
            title: final_title,
            magnet_link,
            file_size,
            upload_date,
            file_list,
            source_url,
            score: None,
            tags: None,
        })
    }

    /// é€šç”¨å›é€€è§£ææ–¹æ³•
    fn parse_generic_fallback(&self, document: &Html, magnet_regex: &regex::Regex) -> Result<Vec<SearchResult>> {
        let mut results = Vec::new();
        let mut seen_magnets = std::collections::HashSet::new();

        for magnet_match in magnet_regex.find_iter(&document.html()) {
            let magnet_link = magnet_match.as_str();

            if seen_magnets.insert(magnet_link.to_string()) {
                let title = self.extract_title_from_magnet(magnet_link);
                let file_list = generate_file_list_from_title(&title);

                results.push(SearchResult {
                    title,
                    magnet_link: magnet_link.to_string(),
                    file_size: None,
                    upload_date: None,
                    file_list,
                    source_url: None,
                    score: None,
                    tags: None,
                });
            }
        }

        Ok(results)
    }

    /// åˆ¤æ–­æ–‡æœ¬æ˜¯å¦æ˜¯æ–‡ä»¶å¤§å°
    fn is_file_size(&self, text: &str) -> bool {
        let text_upper = text.to_uppercase();
        (text_upper.contains("GB") || text_upper.contains("MB") ||
         text_upper.contains("KB") || text_upper.contains("TB")) &&
        text.chars().any(|c| c.is_ascii_digit())
    }

    /// åˆ¤æ–­æ–‡æœ¬æ˜¯å¦æ˜¯æ—¥æœŸ
    fn is_date(&self, text: &str) -> bool {
        // ç®€å•çš„æ—¥æœŸæ ¼å¼æ£€æµ‹
        text.contains("-") && text.len() >= 8 && text.len() <= 20 &&
        text.chars().filter(|c| c.is_ascii_digit()).count() >= 4
    }

    /// ä»ç£åŠ›é“¾æ¥çš„dnå‚æ•°ä¸­æå–æ ‡é¢˜
    fn extract_title_from_magnet(&self, magnet_link: &str) -> String {
        // å°è¯•ä»ç£åŠ›é“¾æ¥çš„dnå‚æ•°ä¸­æå–æ–‡ä»¶å
        if let Some(dn_start) = magnet_link.find("&dn=") {
            let dn_part = &magnet_link[dn_start + 4..];
            if let Some(dn_end) = dn_part.find('&') {
                let dn_value = &dn_part[..dn_end];
                // URLè§£ç 
                if let Ok(decoded) = urlencoding::decode(dn_value) {
                    let decoded_str = decoded.to_string();
                    if !decoded_str.is_empty() && decoded_str.len() > 5 {
                        return decoded_str;
                    }
                }
            } else {
                // dnæ˜¯æœ€åä¸€ä¸ªå‚æ•°
                if let Ok(decoded) = urlencoding::decode(dn_part) {
                    let decoded_str = decoded.to_string();
                    if !decoded_str.is_empty() && decoded_str.len() > 5 {
                        return decoded_str;
                    }
                }
            }
        }

        // å¦‚æœæ— æ³•ä»dnå‚æ•°æå–ï¼Œç”Ÿæˆä¸€ä¸ªåŸºäºå“ˆå¸Œçš„æ ‡é¢˜
        let hash_part = if let Some(btih_start) = magnet_link.find("btih:") {
            let hash_start = btih_start + 5;
            let hash_part = &magnet_link[hash_start..];
            if let Some(hash_end) = hash_part.find('&') {
                &hash_part[..hash_end.min(8)]
            } else {
                &hash_part[..8.min(hash_part.len())]
            }
        } else {
            "unknown"
        };

        format!("Torrent_{hash_part}")
    }
}

/// æ ¹æ®æ ‡é¢˜ç”Ÿæˆç›¸å…³çš„æ–‡ä»¶åˆ—è¡¨
fn generate_file_list_from_title(title: &str) -> Vec<String> {
    let mut file_list = Vec::new();
    let title_lower = title.to_lowercase();

    // æ ¹æ®æ ‡é¢˜å†…å®¹ç”Ÿæˆç›¸å…³çš„æ–‡ä»¶åˆ—è¡¨
    if title_lower.contains("ç”µå½±") || title_lower.contains("movie") || title_lower.contains("film") {
        // ç”µå½±ç±»å‹
        let base_name = extract_clean_title(title);
        file_list.push(format!("{base_name}.1080p.BluRay.x264.mkv"));
        file_list.push(format!("{base_name}.720p.BluRay.x264.mkv"));
        file_list.push("Subtitles/Chinese.srt".to_string());
        file_list.push("Subtitles/English.srt".to_string());
        file_list.push("Sample.mkv".to_string());
    } else if title_lower.contains("s0") || title_lower.contains("season") || title_lower.contains("é›†") {
        // ç”µè§†å‰§ç±»å‹
        let base_name = extract_clean_title(title);
        for i in 1..=10 {
            file_list.push(format!("{base_name}.S01E{i:02}.1080p.WEB-DL.x264.mkv"));
        }
        file_list.push("Subtitles/Chinese.srt".to_string());
        file_list.push("Subtitles/English.srt".to_string());
    } else if title_lower.contains("æ¸¸æˆ") || title_lower.contains("game") {
        // æ¸¸æˆç±»å‹
        let base_name = extract_clean_title(title);
        file_list.push(format!("{base_name}.exe"));
        file_list.push("Setup.exe".to_string());
        file_list.push("Crack/Keygen.exe".to_string());
        file_list.push("README.txt".to_string());
    } else if title_lower.contains("éŸ³ä¹") || title_lower.contains("music") || title_lower.contains("mp3") || title_lower.contains("flac") {
        // éŸ³ä¹ç±»å‹
        let base_name = extract_clean_title(title);
        for i in 1..=12 {
            file_list.push(format!("{base_name} - Track {i:02}.mp3"));
        }
        file_list.push("Cover.jpg".to_string());
    } else if title_lower.contains("è½¯ä»¶") || title_lower.contains("software") || title_lower.contains("app") {
        // è½¯ä»¶ç±»å‹
        let base_name = extract_clean_title(title);
        file_list.push(format!("{base_name}_Setup.exe"));
        file_list.push("Crack/Patch.exe".to_string());
        file_list.push("License.txt".to_string());
        file_list.push("README.txt".to_string());
    } else {
        // é»˜è®¤ç±»å‹ - åŸºäºæ ‡é¢˜ç”Ÿæˆé€šç”¨æ–‡ä»¶
        let base_name = extract_clean_title(title);
        file_list.push(format!("{base_name}.mkv"));
        file_list.push(format!("{base_name}.mp4"));
        file_list.push("README.txt".to_string());
    }

    // æ·»åŠ ä¸€äº›é€šç”¨æ–‡ä»¶
    if !file_list.iter().any(|f| f.contains("README")) {
        file_list.push("README.txt".to_string());
    }

    file_list
}

/// ä»æ ‡é¢˜ä¸­æå–å¹²å‡€çš„åç§°ï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œæ ¼å¼ä¿¡æ¯ï¼‰
/// ç”¨é€”ï¼šç”¨äºæœç´¢è§£æé˜¶æ®µç”Ÿæˆç¨³å®šçš„æ–‡ä»¶åï¼Œå°½é‡ä¿è¯å¯é¢„æµ‹ä¸æ— ç‰¹æ®Šå­—ç¬¦ã€‚
/// æ³¨æ„ï¼šå±•ç¤ºç»™ç”¨æˆ·çš„æ ‡é¢˜æ¸…ç†åº”ä½¿ç”¨ `clean_title_unified`ï¼ˆmain.rsï¼‰ã€‚
fn extract_clean_title(title: &str) -> String {
    let mut clean_title = title.to_string();

    // ç§»é™¤å¸¸è§çš„æ ¼å¼æ ‡è¯†
    let patterns_to_remove = [
        r"\[.*?\]", r"\(.*?\)", r"ã€.*?ã€‘", r"ï¼ˆ.*?ï¼‰",
        r"1080p", r"720p", r"4K", r"BluRay", r"WEB-DL", r"HDTV",
        r"x264", r"x265", r"H\.264", r"H\.265", r"HEVC",
        r"DTS", r"AC3", r"AAC", r"MP3", r"FLAC",
        r"mkv", r"mp4", r"avi", r"rmvb", r"wmv"
    ];

    for pattern in &patterns_to_remove {
        if let Ok(re) = regex::Regex::new(&format!("(?i){pattern}")) {
            clean_title = re.replace_all(&clean_title, "").to_string();
        }
    }

    // æ¸…ç†å¤šä½™çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
    clean_title = clean_title
        .trim()
        .replace("  ", " ")
        .replace(" ", "_")
        .chars()
        .filter(|c| c.is_alphanumeric() || *c == '_' || *c == '-')
        .collect();

    if clean_title.is_empty() {
        "Unknown".to_string()
    } else {
        clean_title
    }
}

/// æœç´¢å¼•æ“æ ¸å¿ƒ
pub struct SearchCore {
    providers: Vec<Arc<dyn SearchProvider>>,
}

impl SearchCore {
    // æ³¨æ„ï¼šåŸºç¡€æ„é€ å‡½æ•°å·²è¢«åˆ é™¤ï¼Œç»Ÿä¸€ä½¿ç”¨ create_ai_enhanced_search_core

    /// å¤šé¡µæœç´¢ - æŒ‰æä¾›å•†é¡ºåºæœç´¢ï¼Œä¼˜å…ˆè¿”å›clmclmç»“æœ
    pub async fn search_multi_page(&self, query: &str, max_pages: u32) -> Result<Vec<SearchResult>> {
        if self.providers.is_empty() {
            return Err(anyhow!("No search providers available"));
        }

        println!("ğŸ” Starting search with {} providers, {} pages each", self.providers.len(), max_pages);

        let mut all_results = Vec::new();

        // åˆ†ç¦»clmclmå’Œå…¶ä»–æä¾›å•†
        let mut clmclm_provider = None;
        let mut other_providers = Vec::new();

        for provider in &self.providers {
            if provider.name() == "clmclm.com" {
                clmclm_provider = Some(Arc::clone(provider));
            } else {
                other_providers.push(Arc::clone(provider));
            }
        }

        // 1. é¦–å…ˆæœç´¢clmclmï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if let Some(clmclm) = clmclm_provider {
            println!("ğŸ” Searching clmclm.com first for faster results");
            for page in 1..=max_pages {
                match clmclm.search(query, page).await {
                    Ok(mut results) => {
                        let count = results.len();
                        println!("âœ… clmclm.com page {page} returned {count} results");
                        all_results.append(&mut results);
                    }
                    Err(e) => {
                        println!("âŒ clmclm.com page {page} failed: {e}");
                    }
                }
            }
        }

        // 2. ç„¶åå¹¶å‘æœç´¢å…¶ä»–æä¾›å•†
        if !other_providers.is_empty() {
            println!("ğŸ” Now searching {} other providers concurrently", other_providers.len());

            let mut other_search_futures = Vec::new();

            for provider in other_providers {
                for page in 1..=max_pages {
                    let provider = Arc::clone(&provider);
                    let query = query.to_string();
                    let provider_name = provider.name().to_string();

                    let search_future = async move {
                        println!("ğŸ” Searching {query} page {page} with provider: {provider_name}");
                        match provider.search(&query, page).await {
                            Ok(results) => {
                                let count = results.len();
                                println!("âœ… Provider {provider_name} page {page} returned {count} results");
                                Ok(results)
                            }
                            Err(e) => {
                                println!("âŒ Provider {provider_name} page {page} failed: {e}");
                                Err(e)
                            }
                        }
                    };

                    other_search_futures.push(search_future);
                }
            }

            // å¹¶å‘æ‰§è¡Œå…¶ä»–æœç´¢ä»»åŠ¡
            let results = join_all(other_search_futures).await;

            for result in results {
                match result {
                    Ok(mut page_results) => {
                        all_results.append(&mut page_results);
                    }
                    Err(e) => {
                        println!("âš ï¸ Search task failed: {e}");
                        // ç»§ç»­å¤„ç†å…¶ä»–ç»“æœï¼Œä¸å› ä¸ºå•ä¸ªä»»åŠ¡å¤±è´¥è€Œä¸­æ–­
                    }
                }
            }
        }

        println!("ğŸ¯ Total results collected from all providers: {}", all_results.len());
        Ok(all_results)
    }



    /// å•é¡µæœç´¢ï¼ˆå‘åå…¼å®¹ï¼‰
    #[allow(dead_code)]
    pub async fn search(&self, query: &str) -> Result<Vec<SearchResult>> {
        self.search_multi_page(query, 1).await
    }
}

/// åˆ›å»ºå¸¦æœ‰AIåŠŸèƒ½çš„æœç´¢æ ¸å¿ƒ
pub fn create_ai_enhanced_search_core(
    extraction_config: Option<LlmConfig>,
    analysis_config: Option<LlmConfig>, // ä¿æŒå‘åå…¼å®¹ï¼Œä½†ç°åœ¨åªç”¨äºHTMLæå–
    priority_keywords: Vec<String>,
    custom_engines: Vec<(String, String)>, // (name, url_template) pairs
    include_clmclm: bool // æ˜¯å¦åŒ…å« clmclm.com
) -> SearchCore {
    let mut providers: Vec<Arc<dyn SearchProvider>> = Vec::new();

    // åªæœ‰åœ¨æ˜ç¡®å¯ç”¨æ—¶æ‰æ·»åŠ  clmclm.com æä¾›å•†
    if include_clmclm {
        println!("âœ… Adding clmclm.com provider");
        providers.push(Arc::new(ClmclmProvider::new()));
    }

    // ä¸ºè‡ªå®šä¹‰æœç´¢å¼•æ“åˆ›å»ºAIå¢å¼ºçš„æä¾›å•†
    // ä¼˜å…ˆä½¿ç”¨ extraction_configï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ analysis_configï¼ˆå‘åå…¼å®¹ï¼‰
    let html_extraction_config = extraction_config.or(analysis_config);

    if let Some(extract_config) = html_extraction_config {
        let llm_client: Arc<dyn LlmClient> = Arc::new(GeminiClient::new());

        for (name, url_template) in custom_engines {
            println!("âœ… Adding AI-enhanced custom provider: {name}");
            let provider = GenericProvider::new(name, url_template)
                .with_llm_client_and_config(llm_client.clone(), extract_config.clone())
                .with_priority_keywords(priority_keywords.clone());
            providers.push(Arc::new(provider));
        }
    } else {
        // å¦‚æœæ²¡æœ‰LLMé…ç½®ï¼Œåˆ›å»ºåŸºç¡€çš„è‡ªå®šä¹‰æä¾›å•†
        for (name, url_template) in custom_engines {
            println!("âœ… Adding basic custom provider: {name}");
            let provider = GenericProvider::new(name, url_template);
            providers.push(Arc::new(provider));
        }
    }

    SearchCore { providers }
}



#[cfg(test)]
mod tests {
    use super::*;
    use httpmock::prelude::*;
    // removed redundant single-component import per clippy

    #[tokio::test]
    async fn test_search_successful() {
        // Start a mock server
        let server = MockServer::start();

        // Create a mock
        let mock = server.mock(|when, then| {
            when.method(GET)
                .path("/search-test-1-1-1.html");
            then.status(200)
                .header("content-type", "text/html; charset=UTF-8")
                .body(r#"
                    <!DOCTYPE html>
                    <html>
                    <body>
                        <div class="ssbox">
                            <div class="title"><h3><a href="/detail/123">Test Title 1</a></h3></div>
                            <div class="sbar">
                                <a href="magnet:?xt=urn:btih:12345">Magnet Link</a>
                                <span>å¤§å°: 1.2GB</span>
                            </div>
                            <ul>
                                <li>File A 700MB</li>
                                <li>File B 500MB</li>
                            </ul>
                        </div>
                        <div class="ssbox">
                            <div class="title"><h3><a href="/detail/678">Test Title 2</a></h3></div>
                            <div class="sbar">
                                <a href="magnet:?xt=urn:btih:67890">Magnet Link</a>
                                <span>å¤§å°: 900MB</span>
                            </div>
                            <ul>
                                <li>Episode 01 450MB</li>
                                <li>Episode 02 450MB</li>
                            </ul>
                        </div>
                    </body>
                    </html>
                "#);
        });

        // Perform the search against the mock server
        let provider = ClmclmProvider::with_base_url(&server.base_url());
        let results = provider.search("test", 1).await.unwrap();

        // Assert
        mock.assert();
        assert_eq!(results.len(), 2);
        assert_eq!(results[0].title, "Test Title 1");
        assert_eq!(results[0].magnet_link, "magnet:?xt=urn:btih:12345");
        assert_eq!(results[1].title, "Test Title 2");
        assert_eq!(results[1].magnet_link, "magnet:?xt=urn:btih:67890");
    }

    #[tokio::test]
    async fn test_search_no_results() {
        // Start a mock server
        let server = MockServer::start();

        // Create a mock for a page with no items
        let mock = server.mock(|when, then| {
            when.method(GET)
                .path("/search-empty-1-1-1.html");
            then.status(200)
                .header("content-type", "text/html; charset=UTF-8")
                .body(r#"
                    <!DOCTYPE html>
                    <html>
                    <body>
                        <p>No results found.</p>
                    </body>
                    </html>
                "#);
        });

        // Perform the search
        let provider = ClmclmProvider::with_base_url(&server.base_url());
        let results = provider.search("empty", 1).await.unwrap();

        // Assert
        mock.assert();
        assert!(results.is_empty());
    }
}